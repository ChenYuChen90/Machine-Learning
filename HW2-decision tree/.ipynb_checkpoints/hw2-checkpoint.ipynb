{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fI00-KuddN2u"
   },
   "source": [
    "Mount Google Drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPaW9fmNw4cA",
    "outputId": "d209ff9c-9121-4bc3-a76c-4d14add95c23"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uf6ucZcj6kpK",
    "outputId": "c12265cb-5c01-445d-9c6e-b5f1a77806de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vince\\Desktop\\ML\\HW2\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "# os.chdir(\"/content/drive/MyDrive/....\")  # file path\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvRo67Io4NKF"
   },
   "source": [
    "# **HW2 : Decision Tree and Random Forest**\n",
    "In *assignment 2*, you need to finish :\n",
    "\n",
    "1. Basic Part : Implement a **Decision Tree** model and predict whether the patients in the validation set have diabetes\n",
    "> * Step 1 : Load the input data\n",
    "> * Step 2 : Calculate the Entropy and Information Gain\n",
    "> * Step 3 : Find the Best Split\n",
    "> * Step 4 : Split into 2 branches\n",
    "> * Step 5 : Build decision tree\n",
    "> * Step 6 : Save the answers from step2 to step5\n",
    "> * Step 7 : Split data into training set and validation set\n",
    "> * Step 8 : Train a decision tree model with training set\n",
    "> * Step 9 : Predict the cases in the *validation set* by using the model trained in *Step8*\n",
    "> * Step 10 : Calculate the f1-score of your predictions in *Step9*\n",
    "> * Step 11 : Write the Output File\n",
    "\n",
    "2. Advanced Part : Build a **Random Forest** model to make predictions\n",
    "> * Step 1 : Load the input data\n",
    "> * Step 2 : Load the test data\n",
    "> * Step 3 : Build a random forest\n",
    "> * Step 4 : Predict the cases in the test data by using the model trained in *Step3*\n",
    "> * Step 5 : Save the predictions(from *Step 4*) in a csv file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwVh8lYD4kbV"
   },
   "source": [
    "# **Basic Part** (60%)\n",
    "In this part, your need to implement a Decision Tree model by completing the following given functions.\n",
    "\n",
    "Also, you need to run these functions with the given input variables and save the output in a csv file **hw2_basic.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2ibEyDa46X2"
   },
   "source": [
    "## Import Packages\n",
    "\n",
    "\n",
    "> Note : You **cannot** import any other packages in both basic part and advanced part\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RMjaYVZD6kmb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from numpy import sqrt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrQXqH475G8-"
   },
   "source": [
    "## Step1: Load the input data\n",
    "First, load the input file **hw2_input_basic.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0n3gcL2l6kjb"
   },
   "outputs": [],
   "source": [
    "input_data = pd.read_csv('hw2_input_basic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhtqUTG9Nlyz"
   },
   "source": [
    "## Global attributes\n",
    "Define the global attributes\n",
    "> Note : You **cannot** modify the values of these attributes we given in the basic part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "etfPC94oN_TO"
   },
   "outputs": [],
   "source": [
    "max_depth = 2\n",
    "depth = 0\n",
    "min_samples_split = 2\n",
    "n_features = input_data.shape[1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1FN1Z-tOFOo"
   },
   "source": [
    "> You can add your own global attributes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQ-OYop8ONnv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gey7t_Yx5YML"
   },
   "source": [
    "## Step2 : Calculate the Entropy and Information Gain \n",
    "Calculate the information gain and entropy values before separate data into left subtree and right subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpdNz3ij6keH",
    "outputId": "57b72546-74e6-4c4c-e2f7-a909df40b37d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_entropy =  0.9871377743721863\n"
     ]
    }
   ],
   "source": [
    "def entropy(data):\n",
    "  \"\"\"\n",
    "  This function measures the amount of uncertainty in a probability distribution\n",
    "  args: \n",
    "  * data(type: DataFrame): the data you're calculating for the entropy\n",
    "  return:\n",
    "  * entropy_value(type: float): the data's entropy\n",
    "  \"\"\"\n",
    "  p = len(data[data.diabetes_mellitus == 1])\n",
    "  n = len(data[data.diabetes_mellitus == 0])\n",
    "  if p == 0 or n == 0:\n",
    "    entropy_value = 0\n",
    "  else:\n",
    "    entropy_value = -(p / ( p + n )) * math.log(p / ( p + n ), 2) - (n / ( p + n )) * math.log(n / ( n + p), 2)\n",
    "  #print(entropy_value)\n",
    "  return entropy_value\n",
    "  \n",
    "# [Note] You have to save the value of \"ans_entropy\" into the output file\n",
    "ans_entropy = entropy(input_data)\n",
    "print(\"ans_entropy = \", ans_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zCC_SiU26kbX",
    "outputId": "d27694e6-c5d4-42a7-dba6-d3fb2c7200bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_informationGain =  0.08345988684807149\n"
     ]
    }
   ],
   "source": [
    "def information_gain(data, mask):\n",
    "  \"\"\"\n",
    "  This function will calculate the information gain\n",
    "  args:\n",
    "  * data(type: DataFrame): the data you're calculating for the information gain\n",
    "  * mask(type: Series): partition information(left/right) of current input data, \n",
    "    - boolean 1(True) represents split to left subtree\n",
    "    - boolean 0(False) represents split to right subtree\n",
    "  return:\n",
    "  * ig(type: float): the information gain you can obtain by classify data with this given mask\n",
    "  \"\"\"\n",
    "  left_subtree = pd.DataFrame()\n",
    "  left = 0\n",
    "  right_subtree = pd.DataFrame()\n",
    "  right = 0\n",
    "  for i in range(data.shape[0]):\n",
    "    if mask[i] == True:\n",
    "      left_subtree = pd.concat([left_subtree, data.loc[[i]]])\n",
    "      left += 1\n",
    "    elif mask[i] == False:\n",
    "      right_subtree = pd.concat([right_subtree, data.loc[[i]]])  \n",
    "      right += 1\n",
    "  new_entropy = (left / (right + left)) * entropy(left_subtree) + (right / (right + left)) * entropy(right_subtree)\n",
    "  original_entropy = entropy(data)\n",
    "  ig = original_entropy - new_entropy\n",
    "  return ig\n",
    "\n",
    "# [Note] You have to save the value of \"ans_informationGain\" into your output file\n",
    "temp1 = np.zeros((int(input_data.shape[0]/4), 1), dtype=bool)\n",
    "temp2 = np.ones(((input_data.shape[0]-int(input_data.shape[0]/4), 1)), dtype=bool)\n",
    "temp_mask = np.concatenate((temp1, temp2))\n",
    "df_mask = pd.DataFrame(temp_mask, columns=['mask'])\n",
    "ans_informationGain = information_gain(input_data, df_mask['mask'])\n",
    "print(\"ans_informationGain = \", ans_informationGain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r8mrn7A55if"
   },
   "source": [
    "## Step3 : Find the Best Split\n",
    "Find the best split combination, **feature** and **threshold**, by calculating the information gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6gg7ig18XgM",
    "outputId": "373bb8ac-c05e-4174-a62d-42a1b59c2f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_ig =  0.3522950515812332\n",
      "ans_value =  235.5\n",
      "ans_name =  glucose_apache\n"
     ]
    }
   ],
   "source": [
    "def find_best_split(data):\n",
    "  \"\"\"\n",
    "  This function will find the best split combination of data\n",
    "  args:\n",
    "  * data(type: DataFrame): the input data\n",
    "  return\n",
    "  * best_ig(type: float): the best information gain you obtain\n",
    "  * best_threshold(type: float): the value that splits data into 2 branches\n",
    "  * best_feature(type: string): the feature that splits data into 2 branches\n",
    "  \"\"\"\n",
    "  feature = data.columns\n",
    "  feature_best_info = []\n",
    "  best_ig = -1\n",
    "  best_threshold = -1\n",
    "  best_feature = \"\"\n",
    "  for k in range(data.shape[1]-1):  #expect diabete data\n",
    "    df = data[[feature[k], \"diabetes_mellitus\"]].sort_values([feature[k]]).reset_index(drop=True)\n",
    "    temp_ig = -1\n",
    "    temp_threshold = -1\n",
    "    for i in range(df.shape[0]-1):\n",
    "      if df[feature[k]][i] != df[feature[k]][i+1]:\n",
    "        temp1 = np.zeros((int(i+1), 1), dtype=bool)\n",
    "        temp2 = np.ones(((int(df.shape[0]-i-1), 1)), dtype=bool)\n",
    "        temp_mask = np.concatenate((temp1, temp2))\n",
    "        ig = information_gain(df, temp_mask)\n",
    "        if ig > best_ig:\n",
    "          best_ig = ig\n",
    "          best_threshold = (df[feature[k]][i] + df[feature[k]][i+1]) / 2\n",
    "          best_feature = feature[k]\n",
    "  return best_ig, best_threshold, best_feature\n",
    "\n",
    "\n",
    "# [Note] You have to save the value of \"ans_ig\", \"ans_value\", and \"ans_name\" into the output file\n",
    "ans_ig, ans_value, ans_name = find_best_split(input_data)\n",
    "print(\"ans_ig = \", ans_ig)\n",
    "print(\"ans_value = \", ans_value)\n",
    "print(\"ans_name = \", ans_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61hPUYvy6MTB"
   },
   "source": [
    "## Step4 : Split into 2 branches\n",
    "Using the best split combination you find in function *find_best_split()* to split data into Left Subtree and Right Subtree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQRcjzCLCo4R",
    "outputId": "90003c49-eef1-4f53-c7e0-faf6de4ab0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_left =  10\n"
     ]
    }
   ],
   "source": [
    "def make_partition(data, feature, threshold):\n",
    "  \"\"\"\n",
    "  This function will split the data into 2 branches\n",
    "  args:\n",
    "  * data(type: DataFrame): the input data\n",
    "  * feature(type: string): the attribute(column name)\n",
    "  * threshold(type: float): the threshold for splitting the data\n",
    "  return:\n",
    "  * left(type: DataFrame): the divided data that matches(less than or equal to) the assigned feature's threshold\n",
    "  * right(type: DataFrame): the divided data that doesn't match the assigned feature's threshold\n",
    "  \"\"\"\n",
    "  df = data.sort_values([feature]).reset_index(drop = True)\n",
    "  half = -1\n",
    "  for i in range(df.shape[0]):\n",
    "    if df[feature][i] > threshold:\n",
    "      half = i\n",
    "      break\n",
    "  left = df[:half]\n",
    "  right = df[-(df.shape[0] - half):]\n",
    "  return left, right\n",
    "\n",
    "\n",
    "# [Note] You have to save the value of \"ans_left\" into the output file\n",
    "left, right = make_partition(input_data, 'age', 61.0)\n",
    "ans_left = left.shape[0]\n",
    "print(\"ans_left = \", ans_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLzy6Yhg802x"
   },
   "source": [
    "## Step5 : Build Decision Tree\n",
    "Use the above functions to implement the decision tree\n",
    "\n",
    "Instructions: \n",
    "1.  If current depth < max_depth and the remaining number of samples > min_samples_split: continue to classify those samples\n",
    "2.  Use function *find_best_split()* to find the best split combination\n",
    "3.  If the obtained information gain is **greater than 0**: can build a deeper decision tree (add depth)\n",
    "4. Use function *make_partition()* to split the data into two parts\n",
    "5. Save the features and corresponding thresholds (starting from the root) used by the decision tree into *ans_features[]* and *ans_thresholds[]* respectively\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_OAXVddKkvM2"
   },
   "outputs": [],
   "source": [
    "def build_tree(data, max_depth, min_samples_split, depth):\n",
    "  \"\"\"\n",
    "  This function will build the decision tree\n",
    "  args:\n",
    "  * data(type: DataFrame): the data you want to apply to the decision tree\n",
    "  * max_depth: the maximum depth of a decision tree\n",
    "  * min_samples_split: the minimum number of instances required to do partition\n",
    "  * depth: the height of the current decision tree\n",
    "  return:\n",
    "  * subtree: the decision tree structure including root, branch, and leaf (with the attributes and thresholds)\n",
    "  \"\"\"\n",
    "  one = len(data[data.diabetes_mellitus == 1])\n",
    "  zero = len(data[data.diabetes_mellitus == 0])\n",
    "  if one > zero: label = 1\n",
    "  else: label = 0\n",
    "  # check the condition of current depth and the remaining number of samples\n",
    "  if depth < max_depth and data.shape[0] > min_samples_split :\n",
    "    # call find_best_split() to find the best combination\n",
    "    temp_ig, threshold, feature = find_best_split(data)\n",
    "    # check the value of information gain is greater than 0 or not \n",
    "    if temp_ig > 0 :\n",
    "      # update the depth\n",
    "      depth += 1\n",
    "      # call make_partition() to split the data into two parts=\n",
    "      left, right = make_partition(data, feature, threshold)\n",
    "      # If there is no data split to the left tree OR no data split to the left tree\n",
    "      if left.shape[0] == 0 or right.shape[0] == 0 :\n",
    "        # return the label of the majority\n",
    "        return label\n",
    "      else:\n",
    "        question = \"{} {} {}\".format(feature, \"<=\", threshold)\n",
    "        subtree = {question: []}\n",
    "\n",
    "        # call function build_tree() to recursively build the left subtree and right subtree\n",
    "        left_subtree = build_tree(left, max_depth, min_samples_split, depth)\n",
    "        right_subtree = build_tree(right, max_depth, min_samples_split, depth)\n",
    "        if left_subtree == right_subtree:\n",
    "          subtree = left_subtree\n",
    "        else:\n",
    "          subtree[question].append(left_subtree)\n",
    "          subtree[question].append(right_subtree)\n",
    "    else:\n",
    "      # return the label of the majority\n",
    "      return label\n",
    "  else:\n",
    "    # return the label of the majority\n",
    "    return label\n",
    "\n",
    "  return subtree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlIrw9Gu-M9-"
   },
   "source": [
    "An example of the output from *build_tree()* \n",
    "```\n",
    "{'bmi <= 33.5': [1, {'age <= 68.5': [0, 1]}]}\n",
    "```\n",
    "Therefore, \n",
    "```\n",
    "ans_features = ['bmi', 'age']\n",
    "ans_thresholds = [33.5, 68.5]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QW8wm1rD9dlS",
    "outputId": "9c35e708-d331-408d-9a31-4e9be1c14305"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glucose_apache <= 235.5': [{'heart_rate_apache <= 143.5': [0, 1]}, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_features = []\n",
    "ans_thresholds = []\n",
    "def split_tree(Tree):\n",
    "  global ans_features, ans_thresholds\n",
    "  for k, v in Tree.items():\n",
    "    temp = k.split(\" <= \")\n",
    "    ans_features.append(temp[0])\n",
    "    ans_thresholds.append(temp[1])\n",
    "    if isinstance(v[0], dict):\n",
    "      split_tree(v[0])\n",
    "    elif isinstance(v[1], dict):\n",
    "      split_tree(v[1])\n",
    "    else:\n",
    "      return\n",
    "  return\n",
    "decisionTree = build_tree(input_data, max_depth, min_samples_split, depth)\n",
    "split_tree(decisionTree)\n",
    "decisionTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_n0BfNSGejN",
    "outputId": "9d60584f-1159-4f8a-8a53-81947db1c746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glucose_apache', 'heart_rate_apache']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Note] You have to save the features in the \"decisionTree\" structure (from root to branch and leaf) into the output file\n",
    "ans_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6H9zkN_GgK-",
    "outputId": "69291563-d5ce-4bb1-9221-31483363c58b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['235.5', '143.5']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Note] You have to save the corresponding thresholds for the features in the \"ans_features\" list into the output file\n",
    "ans_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rP0SU7tTweOX"
   },
   "source": [
    "## Step6 : Save answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sDO36kKEwh6C"
   },
   "outputs": [],
   "source": [
    "basic = []\n",
    "basic.append(ans_entropy)\n",
    "basic.append(ans_informationGain)\n",
    "basic.append(ans_ig)\n",
    "basic.append(ans_value)\n",
    "basic.append(ans_name)\n",
    "basic.append(ans_left)\n",
    "for i in range(len(ans_features)):\n",
    "  basic.append(ans_features[i])\n",
    "for m in range(len(ans_thresholds)):\n",
    "  basic.append(ans_thresholds[m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DotyrSZjYKi"
   },
   "source": [
    "## Step7 : Split data\n",
    "Split data into training set and validation set\n",
    "> Note: We have split the data into training set and validation. You **cannot** change the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjNM-n4i5mlG",
    "outputId": "6cbbea64-6390-48cd-c24e-8ae0fe320fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 10)\n",
      "(20, 10)\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "num_train = 20\n",
    "num_validation = 10\n",
    "\n",
    "training_data = input_data.iloc[:num_train]\n",
    "validation_data = input_data.iloc[-num_validation:]\n",
    "\n",
    "y_train = training_data[[\"diabetes_mellitus\"]]\n",
    "x_train = training_data.drop(['diabetes_mellitus'], axis=1)\n",
    "y_validation = validation_data[[\"diabetes_mellitus\"]]\n",
    "x_validation = validation_data.drop(['diabetes_mellitus'], axis=1)\n",
    "y_validation = y_validation.values.flatten()\n",
    "print(input_data.shape)\n",
    "print(training_data.shape)\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfKSt2gH74Uu"
   },
   "source": [
    "## Step8 to Step10 : Make predictions with a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZqSVoJ48a3-"
   },
   "source": [
    "Define the attributions of the decision tree\n",
    "> You **cannot** modify the values of these attributes in this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vSlZ7FVB8eau"
   },
   "outputs": [],
   "source": [
    "max_depth = 2\n",
    "depth = 0\n",
    "min_samples_split = 2\n",
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrK-YqLmLH8p"
   },
   "source": [
    "We have finished the function '*classify_data()*' below, however, you can modify this function if you prefer completing it on your own way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0piZ0blpFXVq"
   },
   "outputs": [],
   "source": [
    "def classify_data(instance, tree):\n",
    "  \"\"\"\n",
    "  This function will predict/classify the input instance\n",
    "  args:\n",
    "  * instance: a instance(case) to be predicted\n",
    "  return:\n",
    "  * answer: the prediction result (the classification result)\n",
    "  \"\"\"\n",
    "  equation = list(tree.keys())[0] \n",
    "  if equation.split()[1] == '<=':\n",
    "    temp_feature = equation.split()[0]\n",
    "    temp_threshold = equation.split()[2]\n",
    "    if instance[temp_feature] > float(temp_threshold):\n",
    "      answer = tree[equation][1]\n",
    "    else:\n",
    "      answer = tree[equation][0]\n",
    "  else:\n",
    "    if instance[equation.split()[0]] in (equation.split()[2]):\n",
    "      answer = tree[equation][0]\n",
    "    else:\n",
    "      answer = tree[equation][1]\n",
    "\n",
    "  if not isinstance(answer, dict):\n",
    "    return answer\n",
    "  else:\n",
    "    return classify_data(instance, answer)\n",
    "\n",
    "\n",
    "def make_prediction(tree, data):\n",
    "  \"\"\"\n",
    "  This function will use your pre-trained decision tree to predict the labels of all instances in data\n",
    "  args:\n",
    "  * tree: the decision tree\n",
    "  * data: the data to predict\n",
    "  return:\n",
    "  * y_prediction: the predictions\n",
    "  \"\"\"\n",
    "  \n",
    "  # [Note] You can call the function classify_data() to predict the label of each instance\n",
    "  y_prediction = []\n",
    "  for i in range(data.index.start, data.index.stop):\n",
    "    y_prediction.append(classify_data(data.loc[i], tree))\n",
    "  return y_prediction\n",
    "\n",
    "\n",
    "def calculate_score(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  This function will calculate the f1-score of the predictions\n",
    "  args:\n",
    "  * y_true: the ground truth\n",
    "  * y_pred: the predictions\n",
    "  return:\n",
    "  * score: the f1-score\n",
    "  \"\"\"\n",
    "  score = f1_score(y_true, y_pred)\n",
    "  \n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3IEu3z3s9TDu",
    "outputId": "3a8a86a2-865e-4f2a-e28d-6c1e25f9e3bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_f1score =  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "decision_tree = build_tree(training_data, max_depth, min_samples_split, depth)\n",
    "y_pred = make_prediction(decision_tree, x_validation)\n",
    "\n",
    "# [Note] You have to save the value of \"ans_f1score\" the your output file\n",
    "ans_f1score = calculate_score(y_validation, y_pred)\n",
    "print(\"ans_f1score = \", ans_f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzzOKOwn-kod"
   },
   "source": [
    "## Step11 : Write the Output File\n",
    "Save all of your answers in a csv file, named as **hw2_basic.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0zsaWPL2qXn",
    "outputId": "db757d70-26bf-42cb-d50d-5b3c22ddc49a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9871377743721863, 0.08345988684807149, 0.3522950515812332, 235.5, 'glucose_apache', 10, 'glucose_apache', 'heart_rate_apache', '235.5', '143.5', 0.6666666666666666]\n"
     ]
    }
   ],
   "source": [
    "ans_path = 'hw2_basic.csv'\n",
    "\n",
    "# [Note] You have to save the value of \"ans_f1score\" into the output file\n",
    "basic.append(ans_f1score)\n",
    "print(basic)\n",
    "\n",
    "pd.DataFrame(basic).to_csv(ans_path, header = None, index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV25IjM7_aEn"
   },
   "source": [
    "# **Advanced Part** (35%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knH1Ih0Pha7X"
   },
   "source": [
    "## Step1: Load the input data\n",
    "First, load the input file **hw2_input_advanced.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "FthBdLxRhi9W"
   },
   "outputs": [],
   "source": [
    "advanced_data = pd.read_csv('hw2_input_advanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqLH49oBndRh"
   },
   "source": [
    "You can split *advanced_data* into training set and validaiton set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9l0hLPVjncam"
   },
   "outputs": [],
   "source": [
    "total_instance = len(advanced_data)\n",
    "advanced_train = int(0.8 * total_instance)\n",
    "advanced_pred = int(0.2 * total_instance)\n",
    "training_data = advanced_data[:advanced_train]\n",
    "validation_data = advanced_data[-advanced_pred:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFgbUY_ajVOK"
   },
   "source": [
    "## Step2 : Load the test data\n",
    "Load the input file **hw2_input_test.csv** to make predictions with the pre-trained random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3hW542KWNxVF"
   },
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('hw2_input_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH-0DxyR9qWn"
   },
   "source": [
    "## Step3 : Build a Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xbLxFW597FG"
   },
   "source": [
    "Define the attributions of the random forest\n",
    "> * You **can** modify the values of these attributes in advanced part\n",
    "> * Each tree can have different attribute values\n",
    "> * There must be **at least** 3 decision trees in the random forest model\n",
    "> * Must use function *build_tree()* to build a random forest model\n",
    "> * These are the parameters you can adjust : \n",
    "\n",
    "\n",
    "    ```\n",
    "    max_depth = \n",
    "    depth = 0\n",
    "    min_samples_split = \n",
    "    \n",
    "    # total number of trees in a random forest\n",
    "    n_trees = \n",
    "\n",
    "    # number of features to train a decision tree\n",
    "    n_features = \n",
    "\n",
    "    # the ratio to select the number of instances\n",
    "    sample_size = \n",
    "    n_samples = int(training_data.shape[0] * sample_size)\n",
    "    ```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "LD8ndJ8ymzG3"
   },
   "outputs": [],
   "source": [
    "# Define the attributes\n",
    "max_depth = 5\n",
    "depth = 0\n",
    "min_samples_split = 20\n",
    "\n",
    "n_trees = 31\n",
    "\n",
    "n_features = 12\n",
    "n_samples = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hVl66f1aU36-"
   },
   "outputs": [],
   "source": [
    "def build_forest(data, n_trees, n_features, n_samples):\n",
    "  \"\"\"\n",
    "  This function will build a random forest.\n",
    "  args:\n",
    "  * data: all data that can be used to train a random forest\n",
    "  * n_trees: total number of tree\n",
    "  * n_features: number of features\n",
    "  * n_samples: number of instances\n",
    "  return:\n",
    "  * forest: a random forest with 'n_trees' of decision tree\n",
    "  \"\"\"\n",
    "  global max_depth\n",
    "  global min_samples_split\n",
    "  dpth = 0\n",
    "  feature = list(data.columns)\n",
    "  feature.remove(\"diabetes_mellitus\")\n",
    "  forest = []\n",
    "  # must reuse function build_tree()\n",
    "  for i in range(n_trees):\n",
    "    temp_feature = random.sample(feature, n_features)\n",
    "    temp_feature.append(\"diabetes_mellitus\")\n",
    "    temp_data = data[temp_feature].sample(n = n_samples).reset_index(drop = True)\n",
    "    temp_tree = build_tree(temp_data, max_depth, min_samples_split, depth)\n",
    "    print(temp_tree)\n",
    "    forest.append(temp_tree)\n",
    "  return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "zylo6C51m3OJ",
    "outputId": "25026c75-92c2-41f8-8903-01b1fc388277"
   },
   "outputs": [],
   "source": [
    "forest = build_forest(training_data, n_trees, n_features, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZb6EEYnnO05"
   },
   "source": [
    "## Step4 : Make predictions with the random forest\n",
    "> Note: Please print the f1-score of the predictions of each decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UbHMZnMDnWpG"
   },
   "outputs": [],
   "source": [
    "def make_prediction_forest(forest, data):\n",
    "  \"\"\"\n",
    "  This function will use the pre-trained random forest to make the predictions\n",
    "  args:\n",
    "  * forest: the random forest\n",
    "  * data: the data used to predict\n",
    "  return:\n",
    "  * y_prediction: the predicted results\n",
    "  \"\"\"\n",
    "  temp_pred = []\n",
    "  y_prediction = []\n",
    "  for i in forest:\n",
    "    temp_pred.append(make_prediction(i, data))\n",
    "  for i in range(len(temp_pred[0])):\n",
    "    ct_one = 0\n",
    "    ct_zero = 0\n",
    "    for j in range(len(temp_pred)):\n",
    "      if temp_pred[j][i] == 0:\n",
    "        ct_zero += 1\n",
    "      elif temp_pred[j][i] == 1:\n",
    "        ct_one += 1\n",
    "    if ct_zero < ct_one:\n",
    "      y_prediction.append(1)\n",
    "    else:\n",
    "      y_prediction.append(0)\n",
    "  return (temp_pred, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqKt9_X4jjOl"
   },
   "source": [
    "### 自己測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "yo8PxoyBiqI7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans_f1score =  0.6751592356687898\n",
      "ans_f1score =  0.6868327402135231\n",
      "ans_f1score =  0.4566210045662101\n",
      "ans_f1score =  0.5156462585034014\n",
      "ans_f1score =  0.6645119586296057\n",
      "ans_f1score =  0.5268456375838926\n",
      "ans_f1score =  0.23853211009174313\n",
      "ans_f1score =  0.7129237288135594\n",
      "ans_f1score =  0.5773087071240106\n",
      "ans_f1score =  0.6290580095795636\n",
      "ans_f1score =  0.6089552238805971\n",
      "ans_f1score =  0.6321177223288547\n",
      "ans_f1score =  0.6695491043854231\n",
      "ans_f1score =  0.6698369565217391\n",
      "ans_f1score =  0.6899516389038152\n",
      "ans_f1score =  0.532919254658385\n",
      "ans_f1score =  0.5741176470588235\n",
      "ans_f1score =  0.6306429548563611\n",
      "ans_f1score =  0.5426229508196722\n",
      "ans_f1score =  0.4642857142857143\n",
      "ans_f1score =  0.5280216070222823\n",
      "ans_f1score =  0.4477124183006536\n",
      "ans_f1score =  0.5719360568383659\n",
      "ans_f1score =  0.48578016910069177\n",
      "ans_f1score =  0.6869514335868929\n",
      "ans_f1score =  0.444076222038111\n",
      "ans_f1score =  0.5302390998593529\n",
      "ans_f1score =  0.4826629680998613\n",
      "ans_f1score =  0.47241867043847247\n",
      "ans_f1score =  0.6840390879478827\n",
      "ans_f1score =  0.6003016591251885\n",
      "total_f1score =  0.6962457337883959\n"
     ]
    }
   ],
   "source": [
    "forest_x_validation = validation_data.drop(['diabetes_mellitus'], axis=1)\n",
    "forest_y_validation = validation_data[[\"diabetes_mellitus\"]]\n",
    "forest_y_validation = forest_y_validation.values.flatten()\n",
    "\n",
    "\n",
    "(tree_y_pred, forest_y_pred) = make_prediction_forest(forest, forest_x_validation)\n",
    "\n",
    "# [Note] You have to save the value of \"ans_f1score\" the your output file\n",
    "for i in tree_y_pred:\n",
    "  ans_f1score = calculate_score(forest_y_validation, i)\n",
    "  print(\"ans_f1score = \", ans_f1score)\n",
    "total_f1scoe = calculate_score(forest_y_validation, forest_y_pred)\n",
    "print(\"total_f1score = \", total_f1scoe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfgA6A5sjct5"
   },
   "source": [
    "### 實際要測的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Hcd70ubwgHq4"
   },
   "outputs": [],
   "source": [
    "(tree_y_pred, y_pred_test) = make_prediction_forest(forest, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ufa5bP9HveO"
   },
   "source": [
    "## Step5 : Write the Output File\n",
    "Save your predictions from the **random forest** in a csv file, named as **hw2_advanced.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XdAQcE41JJYB"
   },
   "outputs": [],
   "source": [
    "advanced = []\n",
    "for i in range(len(y_pred_test)):\n",
    "  advanced.append(y_pred_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4QYarsUXCjm"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Pq121klSHwWO"
   },
   "outputs": [],
   "source": [
    "advanced_path = 'hw2_advanced.csv'\n",
    "pd.DataFrame(advanced).to_csv(advanced_path, header = None, index = None)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
